# S-MSTT v3.3 Configuration for Google Colab
# Full model parameters (same as custom.yaml)

name: CustomModel

# Auto-detected from data (can be left null or explicit)
n_channels: 22
n_samples: 1125
n_classes: 4

# ============================================
# SNN Dynamics (The "Pulse")
# ============================================
t_steps: 16               # Time steps for integration
tau: 2.0                  # Membrane time constant
v_threshold: 0.5          # Threshold (0.5 fixes "dead neuron" issue)
spike_target_rate: 0.25   # Target firing rate (25%)
noise_std: 0.1            # [NEW] Noise injection for dynamic input

# ============================================
# Transformer Architecture
# ============================================
embed_dim: 64             # Feature dimension
depth: 4                  # Number of Transformer blocks
num_heads: 4              # Attention heads
mlp_ratio: 4.0            # Feed-forward expansion ratio
attn_residual_ratio: 0.1  # Gradient flow preservation

# ============================================
# Modules Toggle
# ============================================
use_alignment: true           # Euclidean Alignment (Subject Independence)
use_channel_attention: true   # Motor Cortex Attention
use_multiscale: true          # Mu/Beta/Gamma Encoder
use_learned_aggregation: true # Attention-based temporal pooling

# ============================================
# Regularization
# ============================================
dropout_rate: 0.5         # Dropout
drop_path_rate: 0.1       # Stochastic Depth
alignment_momentum: 0.1   # For Euclidean Alignment

# ============================================
# Motor cortex channel indices (C3, Cz, C4 area)
# ============================================
motor_indices: [6, 7, 8, 9, 10, 11, 12]

# ============================================
# Legacy / Unused (Kept for compatibility if needed)
# ============================================
f1: 32
depth_multiplier: 2
sample_rate: 250
use_preprocessing: false
attention_pool: 8
