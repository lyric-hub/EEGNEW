data:
  dataset_name: BNCI2014_001
  train_subjects:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  val_subjects:
  - 8
  test_subjects:
  - 9
  val_ratio: 0.0
  paradigm:
    n_classes: 4
    fmin: 8.0
    fmax: 35.0
    tmin: -0.5
    tmax: 4.0
    resample: 250
    channels: null
  batch_size: 16
  num_workers: 0
  pin_memory: true
  seed: 42
model:
  name: CustomModel
  n_channels: 22
  n_samples: 1126
  n_classes: 4
  t_steps: 4
  embed_dim: 32
  depth: 3
  num_heads: 4
  mlp_ratio: 4.0
  tau: 2.0
  v_threshold: 1.0
  dropout_rate: 0.3
  spike_target_rate: 0.25
  attn_residual_ratio: 0.1
  use_alignment: true
  use_channel_attention: true
  use_multiscale: true
  use_learned_aggregation: true
  alignment_momentum: 0.1
  motor_indices:
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  f1: 32
  depth_multiplier: 2
  sample_rate: 250
  use_preprocessing: false
  attention_pool: 8
training:
  optimizer:
    name: AdamW
    lr: 0.001
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.999
  scheduler:
    name: CosineAnnealingLR
    T_max: 100
    eta_min: 1.0e-06
  epochs: 200
  gradient_clip: 1.0
  spike_loss_weight: 1.0
  resume_from: models/best_model.pt
  early_stopping:
    enabled: true
    patience: 30
    min_delta: 0.001
    monitor: val_loss
  checkpoint:
    save_best: true
    save_last: true
    monitor: val_accuracy
  logging:
    log_every_n_steps: 10
    use_mlflow: true
experiment_name: eeg-mi-classification
paths:
  data_raw: ${hydra:runtime.cwd}/data/raw
  data_processed: ${hydra:runtime.cwd}/data/processed
  models: ${hydra:runtime.cwd}/models
  outputs: ${hydra:runtime.cwd}/outputs
seed: 42
device: auto
